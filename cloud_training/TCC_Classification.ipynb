{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819b8c0-2b45-4fe5-b86a-9769ad46beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0af566-4fca-46d5-933a-27890835a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mo --saved_model_dir ./000000001/ --data_type FP32 --output_dir models/resnet_50/FP32 --input_shape [1,180,180,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efad1f9-db9b-4261-8ab7-bd04708794ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mo --saved_model_dir ./000000001/ --data_type FP16 --output_dir models/resnet_50/FP16 --input_shape [1,180,180,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9b765-0425-4fce-a823-ee67d75b2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ov_classify_job.sh\n",
    "\n",
    "INPUT=$1\n",
    "FP_MODEL=$2\n",
    "DEVICE=$3\n",
    "OUTPUT=$4\n",
    "\n",
    "# Follow this order of setting up environment for openVINO 2022.1.0.553\n",
    "echo \"Activating a Python virtual environment from ${VENV_PATH}...\"\n",
    "source ${VENV_PATH}/bin/activate\n",
    "echo \"Activating OpenVINO variables from ${OPENVINO_RUNTIME}...\"\n",
    "source ${OPENVINO_RUNTIME}/setupvars.sh\n",
    "\n",
    "# The default path for the job is the user's home directory,\n",
    "#  change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "MODELPATH=./models/resnet_50/${FP_MODEL}/saved_model.xml\n",
    "\n",
    "python3 ov-classify.py -i $INPUT -m $MODELPATH -d $DEVICE -o $OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd3201-c7af-47f3-9d0d-f3fcbbc137c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tf_classify_job.sh\n",
    "\n",
    "INPUT=$1\n",
    "OUTPUT=$2\n",
    "    \n",
    "\n",
    "# Follow this order of setting up environment for openVINO 2022.1.0.553\n",
    "echo \"Activating a Python virtual environment from ${VENV_PATH}...\"\n",
    "source ${VENV_PATH}/bin/activate\n",
    "echo \"Activating OpenVINO variables from ${OPENVINO_RUNTIME}...\"\n",
    "source ${OPENVINO_RUNTIME}/setupvars.sh\n",
    "\n",
    "# The default path for the job is the user's home directory,\n",
    "#  change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "\n",
    "python3 tf-classify.py -i $INPUT -o $OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b6f08-3412-4425-9add-b3df11b8a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep compnode | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602f42c-6012-4ba2-a9b5-e69270b10b02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa055779-51af-4af7-8824-b9785098ef65",
   "metadata": {},
   "source": [
    "### OpenVINO FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7a50a-d8ca-4049-8cf8-837f12c82691",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_cpu_ov_fp32 = !qsub ov_classify_job.sh -l nodes=1:idc073 -F \"./inference_images/401.jpg FP32 CPU ./results/cpu_ov_fp32/ \" -N classify_cpu_ov_fp32 -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_cpu_ov_fp32[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db95002-dc35-43a2-9c9f-510bf1930e10",
   "metadata": {},
   "source": [
    "### Tensorflow FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7259397-3d35-42d4-a592-9d02fe26c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_cpu_tf_fp32 = !qsub tf_classify_job.sh -l nodes=1:idc073 -F \"./inference_images/401.jpg ./results/core_ov/\" -N classify_cpu_tf_fp32 -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_cpu_tf_fp32[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6550fcd-f0f6-4352-b4a2-322d280852d0",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ed76a-2caf-494c-931c-fa735a2141fe",
   "metadata": {},
   "source": [
    "### OpenVINO FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2e356-6223-426f-bf04-0bf2c19b48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu_ov_fp32 = !qsub ov_classify_job.sh -l nodes=1:idc073 -F \"./inference_images/401.jpg FP32 GPU ./results/gpu_ov_fp32/ \" -N classify_gpu_ov_fp32 -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_gpu_ov_fp32[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f231dff-59d3-4bc3-ad61-b1ed34b29f54",
   "metadata": {},
   "source": [
    "### OpenVINO FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc1e8b-ad25-488e-8e21-22375a3ff2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu_ov_fp16 = !qsub ov_classify_job.sh -l nodes=1:idc073 -F \"./inference_images/401.jpg FP16 GPU ./results/gpu_ov_fp16/ \" -N classify_gpu_ov_fp16 -v VENV_PATH,OPENVINO_RUNTIME\n",
    "print(job_id_gpu_ov_fp16[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de42026-612b-450e-9a78-32e80492cda9",
   "metadata": {},
   "source": [
    "### Monitor job status\n",
    "\n",
    "To check the status of the jobs that have been submitted, use the `qstat` command.  The custom Jupyter* Notebook widget `liveQstat()` is provided to display the output of `qstat` with live updates.  \n",
    "\n",
    "Run the following cell to display the current job status with periodic updates. \n",
    "You should see the jobs that you have submitted (referenced by the `JobID` that gets displayed right after you submit the jobs in the previous step).\n",
    "There should also be an extra job in the queue named `jupyterhub-singleuser`: this job is your current Jupyter* Notebook session which is always running.\n",
    "\n",
    "The `S` column shows the current status of each job: \n",
    "- If the status is `Q`, then the job is queued and waiting for available resources\n",
    "- If the status is `R`, then the job is running\n",
    "- If the job is no longer listed, then the job has completed\n",
    "\n",
    "<br><div class=note><i><b>\n",
    "Note: The amount of time spent in the queue depends on the number of users accessing the requested compute nodes. Once the jobs for this sample application begin to run, they should take from 1 to 5 minutes each to complete.\n",
    "</b></i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0856bb-3e47-4731-be76-8b2cddd9052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qarpo.demoutils import *\n",
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efc2a9-4f32-4514-862b-f790c6fa845e",
   "metadata": {},
   "source": [
    "## CPU - OpenVINO FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a945a-0414-4488-ac07-f27e9f327998",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_cpu_ov_fp32 = job_id_cpu_ov_fp32[0].split('.')[0]\n",
    "job_id_cpu_ov_fp32 = 'o'+job_id_cpu_ov_fp32\n",
    "count = 0\n",
    "while not os.path.exists('./classify_cpu_ov_fp32.{}'.format(job_id_cpu_ov_fp32)):  # Wait until the stats file is created.\n",
    "    time.sleep(1)\n",
    "    count = count + 1\n",
    "    assert count != 180, \"Job did not finish\" #Wait to for 3 mins to check if job gets done, and break from the infinite loop\n",
    "cpu_ov = open(\"./classify_cpu_ov_fp32.{}\".format(job_id_cpu_ov_fp32), \"r\")\n",
    "import re\n",
    "stats_cpu_ov = {}\n",
    "for fps_ov in cpu_ov:\n",
    "    if re.search('FPS', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_cpu_ov['FPS_OV'] = str(fps_ov.split(\" \")[1])\n",
    "    if re.search('Inference time', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_cpu_ov['Time_OV'] = str(fps_ov.split(\" \")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a86b4a-c425-4830-ac66-b12d004b5e6d",
   "metadata": {},
   "source": [
    "## CPU - Tensorflow FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d74f8-5999-4a3d-a19b-cdc25d7942dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_cpu_tf_fp32 = job_id_cpu_tf_fp32[0].split('.')[0]\n",
    "job_id_cpu_tf_fp32 = 'o'+job_id_cpu_tf_fp32\n",
    "count = 0\n",
    "while not os.path.exists('./classify_cpu_tf_fp32.{}'.format(job_id_cpu_tf_fp32)):  # Wait until the stats file is created.\n",
    "    time.sleep(1)\n",
    "    count = count + 1\n",
    "    assert count != 180, \"Job did not finish\" #Wait to for 3 mins to check if job gets done, and break from the infinite loop\n",
    "cpu_tf = open(\"./classify_cpu_tf_fp32.{}\".format(job_id_cpu_tf_fp32), \"r\")\n",
    "import re\n",
    "stats_cpu_tf = {}\n",
    "for fps_tf in cpu_tf:\n",
    "    if re.search('FPS', fps_tf):\n",
    "        print(fps_tf)\n",
    "        stats_cpu_tf['FPS_TF'] = str(fps_tf.split(\" \")[1])\n",
    "    if re.search('Inference time', fps_tf):\n",
    "        print(fps_tf)\n",
    "        stats_cpu_tf['Time_TF'] = str(fps_tf.split(\" \")[2])\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ecab4-c6cc-46df-8f06-fc7f71b649dc",
   "metadata": {},
   "source": [
    "## GPU - OpenVINO FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c4a05-36ea-4df7-a5ec-719b10413f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu_ov_fp16 = job_id_gpu_ov_fp16[0].split('.')[0]\n",
    "job_id_gpu_ov_fp16 = 'o'+job_id_gpu_ov_fp16\n",
    "count = 0\n",
    "while not os.path.exists('./classify_gpu_ov_fp16.{}'.format(job_id_gpu_ov_fp16)):  # Wait until the stats file is created.\n",
    "    time.sleep(1)\n",
    "    count = count + 1\n",
    "    assert count != 180, \"Job did not finish\" #Wait to for 3 mins to check if job gets done, and break from the infinite loop\n",
    "gpu_ov_fp16 = open(\"./classify_gpu_ov_fp16.{}\".format(job_id_gpu_ov_fp16), \"r\")\n",
    "import re\n",
    "stats_gpu_fp16 = {}\n",
    "for fps_ov in gpu_ov_fp16:\n",
    "    if re.search('FPS', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_gpu_fp16['FPS_OV'] = str(fps_ov.split(\" \")[1])\n",
    "    if re.search('Inference time', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_gpu_fp16['Time_OV'] = str(fps_ov.split(\" \")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a48e37-c8b2-4d3b-ab64-47950e402539",
   "metadata": {},
   "source": [
    "## GPU - OpenVINO FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad90ae-4286-4e7a-a707-95b172b38d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_gpu_ov_fp32 = job_id_gpu_ov_fp32[0].split('.')[0]\n",
    "job_id_gpu_ov_fp32 = 'o'+job_id_gpu_ov_fp32\n",
    "count = 0\n",
    "while not os.path.exists('./classify_gpu_ov_fp32.{}'.format(job_id_gpu_ov_fp32)):  # Wait until the stats file is created.\n",
    "    time.sleep(1)\n",
    "    count = count + 1\n",
    "    assert count != 180, \"Job did not finish\" #Wait to for 3 mins to check if job gets done, and break from the infinite loop\n",
    "gpu_ov_fp32 = open(\"./classify_gpu_ov_fp32.{}\".format(job_id_gpu_ov_fp32), \"r\")\n",
    "import re\n",
    "stats_gpu_fp32 = {}\n",
    "for fps_ov in gpu_ov_fp32:\n",
    "    if re.search('FPS', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_gpu_fp32['FPS_OV'] = str(fps_ov.split(\" \")[1])\n",
    "    if re.search('Inference time', fps_ov):\n",
    "        print(fps_ov)\n",
    "        stats_gpu_fp32['Time_OV'] = str(fps_ov.split(\" \")[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (OpenVINO 2022.1)",
   "language": "python",
   "name": "openvino_2022.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
