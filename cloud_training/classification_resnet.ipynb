{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1047c7-2d82-48ad-8e34-ea9b496b3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d014c5b-c601-4cd1-85d1-ac67eafa0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \t/home/u154020/cloud_training/models/resnet_50/FP32\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "OpenVINO runtime found in: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Model Optimizer version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnetworkx: installed: 2.5.1, required: ~= 2.6\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[tensorflow]\n",
      "[ WARNING ]  The model contains input(s) with partially defined shapes: name=\"input_1\" shape=\"[-1, 180, 180, 3]\". Starting from the 2022.1 release the Model Optimizer can generate an IR with partially defined input shapes (\"-1\" dimension in the TensorFlow model or dimension with string value in the ONNX model). Some of the OpenVINO plugins require model input shapes to be static, so you should call \"reshape\" method in the Inference Engine and specify static input shapes. For optimal performance, it is still recommended to update input shapes with fixed ones using \"--input\" or \"--input_shape\" command-line parameters.\n",
      "/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, order=order, subok=subok, copy=True)\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u154020/cloud_training/models/resnet_50/FP32/saved_model.xml\n",
      "[ SUCCESS ] BIN file: /home/u154020/cloud_training/models/resnet_50/FP32/saved_model.bin\n",
      "[ SUCCESS ] Total execution time: 47.49 seconds. \n",
      "[ SUCCESS ] Memory consumed: 3085 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n"
     ]
    }
   ],
   "source": [
    "!mo --saved_model_dir ./000000001/ --data_type FP32 --output_dir models/resnet_50/FP32 --scale 256 --mean_values [127,127,127] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ca6be4-1961-43c5-9358-f8a801df41e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \t/home/u154020/cloud_training/models/resnet_50/FP16\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "OpenVINO runtime found in: \t/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "Model Optimizer version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnetworkx: installed: 2.5.1, required: ~= 2.6\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev[tensorflow]\n",
      "[ WARNING ]  The model contains input(s) with partially defined shapes: name=\"input_1\" shape=\"[-1, 180, 180, 3]\". Starting from the 2022.1 release the Model Optimizer can generate an IR with partially defined input shapes (\"-1\" dimension in the TensorFlow model or dimension with string value in the ONNX model). Some of the OpenVINO plugins require model input shapes to be static, so you should call \"reshape\" method in the Inference Engine and specify static input shapes. For optimal performance, it is still recommended to update input shapes with fixed ones using \"--input\" or \"--input_shape\" command-line parameters.\n",
      "/data/venv/openvino_2022.1.0.643/lib/python3.6/site-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, order=order, subok=subok, copy=True)\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u154020/cloud_training/models/resnet_50/FP16/saved_model.xml\n",
      "[ SUCCESS ] BIN file: /home/u154020/cloud_training/models/resnet_50/FP16/saved_model.bin\n",
      "[ SUCCESS ] Total execution time: 48.51 seconds. \n",
      "[ SUCCESS ] Memory consumed: 3089 MB. \n",
      "It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai\n"
     ]
    }
   ],
   "source": [
    "!mo --saved_model_dir ./000000001/ --data_type FP16 --output_dir models/resnet_50/FP16 --scale 256 --mean_values [127,127,127] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dadd2d-8c7b-4a92-be9f-cb442a25d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile classification_job.sh\n",
    "\n",
    "OUTPUT_FILE=$1\n",
    "DEVICE=$2\n",
    "FP_MODEL=$3\n",
    "INPUT_PATH=$4\n",
    "NUM_REQS=5$5\n",
    "\n",
    "echo VENV_PATH=$VENV_PATH\n",
    "echo OPENVINO_RUNTIME=$OPENVINO_RUNTIME\n",
    "echo INPUT_FILE=$INPUT_FILE\n",
    "echo FP_MODEL=$FP_MODEL\n",
    "echo INPUT_TILE=$INPUT_FILE\n",
    "echo NUM_REQS=$NUM_REQS\n",
    "\n",
    "# Follow this order of setting up environment for openVINO 2022.1.0.553\n",
    "echo \"Activating a Python virtual environment from ${VENV_PATH}...\"\n",
    "source ${VENV_PATH}/bin/activate\n",
    "echo \"Activating OpenVINO variables from ${OPENVINO_RUNTIME}...\"\n",
    "source ${OPENVINO_RUNTIME}/setupvars.sh\n",
    "\n",
    "# The default path for the job is the user's home directory,\n",
    "#  change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Make sure that the output directory exists.\n",
    "mkdir -p $OUTPUT_FILE\n",
    "\n",
    "# Set inference model IR files using specified precision\n",
    "MODELPATH=./models/resnet_50/${FP_MODEL}/saved_model.xml\n",
    "LABEL_FILE=./labels.txt\n",
    "INPUT_PATH=\n",
    "\n",
    "\n",
    "python3 python3 classification_demo.py -i $INPUT_PATH -m $MODELPATH -o $OUTPUT_FILE --labels $LABEL_FILE -nireq $NUM_REQS\n",
    "\n",
    "\n",
    "\n",
    "# python3 classification_demo.py -m <path_to_classification_model> \\\n",
    "#                                -i <path_to_folder_with_images> \\\n",
    "#                                 --labels <path_to_file_with_list_of_labels>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (OpenVINO 2022.1)",
   "language": "python",
   "name": "openvino_2022.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
